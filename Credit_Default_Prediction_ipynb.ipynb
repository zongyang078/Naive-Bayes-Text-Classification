{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " ## **1. Data Pre-processing**"
      ],
      "metadata": {
        "id": "GfubSfPpP7v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load the datasets\n",
        "train_url = \"https://raw.githubusercontent.com/mh2t/DS5110/main/Homework/HW4-Train.csv\"\n",
        "valid_url = \"https://raw.githubusercontent.com/mh2t/DS5110/main/Homework/HW4-Validation.csv\"\n",
        "\n",
        "train = pd.read_csv(train_url)\n",
        "valid = pd.read_csv(valid_url)\n",
        "\n",
        "# Add a source flag BEFORE concatenating\n",
        "train[\"source\"] = \"train\"\n",
        "valid[\"source\"] = \"valid\"\n",
        "\n",
        "# Combine training and validation data\n",
        "df = pd.concat([train, valid], axis=0).reset_index(drop=True)\n",
        "\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# 1. Check and handle missing values\n",
        "print(\"Missing values per column:\\n\", df.isna().sum())\n",
        "\n",
        "# If there are very few missing values, we can drop them\n",
        "df = df.dropna()\n",
        "\n",
        "# 2. Separate predictors (X) and target (y)\n",
        "target_col = \"Default_ind\"\n",
        "\n",
        "y = df[target_col]\n",
        "source = df[\"source\"]\n",
        "X = df.drop(columns=[target_col, \"source\"])\n",
        "\n",
        "# 3. Encode categorical variables (States)\n",
        "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "print(\"Categorical columns:\", list(cat_cols))\n",
        "\n",
        "X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
        "\n",
        "# 4. Standardize numerical variables\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Data preprocessing completed.\")\n",
        "print(\"Final shape:\", X_scaled.shape)\n",
        "\n",
        "# 5. Split back into train / valid using 'source'\n",
        "mask_train = (source == \"train\").values\n",
        "mask_valid = (source == \"valid\").values\n",
        "\n",
        "X_train = X_scaled[mask_train]\n",
        "y_train = y[mask_train]\n",
        "\n",
        "X_valid = X_scaled[mask_valid]\n",
        "y_valid = y[mask_valid]\n",
        "\n",
        "print(\"Train size:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation size:\", X_valid.shape, y_valid.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVRaLkrcO1nE",
        "outputId": "abadafee-70de-4338-db1f-4036ad359311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tot_credit_debt', 'avg_card_debt', 'credit_age', 'credit_good_age', 'card_age', 'non_mtg_acc_past_due_12_months_num', 'non_mtg_acc_past_due_6_months_num', 'mortgages_past_due_6_months_num', 'credit_past_due_amount', 'inq_12_month_num', 'card_inq_24_month_num', 'card_open_36_month_num', 'auto_open_ 36_month_num', 'uti_card', 'uti_50plus_pct', 'uti_max_credit_line', 'uti_card_50plus_pct', 'ind_acc_XYZ', 'rep_income', 'States', 'Default_ind', 'source']\n",
            "Missing values per column:\n",
            " tot_credit_debt                          0\n",
            "avg_card_debt                            0\n",
            "credit_age                               0\n",
            "credit_good_age                          0\n",
            "card_age                                 0\n",
            "non_mtg_acc_past_due_12_months_num       0\n",
            "non_mtg_acc_past_due_6_months_num        0\n",
            "mortgages_past_due_6_months_num          0\n",
            "credit_past_due_amount                   0\n",
            "inq_12_month_num                         0\n",
            "card_inq_24_month_num                    0\n",
            "card_open_36_month_num                   0\n",
            "auto_open_ 36_month_num                  0\n",
            "uti_card                                 0\n",
            "uti_50plus_pct                           0\n",
            "uti_max_credit_line                      0\n",
            "uti_card_50plus_pct                   2352\n",
            "ind_acc_XYZ                              0\n",
            "rep_income                            1823\n",
            "States                                   0\n",
            "Default_ind                              0\n",
            "source                                   0\n",
            "dtype: int64\n",
            "Categorical columns: ['States']\n",
            "Data preprocessing completed.\n",
            "Final shape: (19032, 25)\n",
            "Train size: (16559, 25) (16559,)\n",
            "Validation size: (2473, 25) (2473,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Logistic Regression Model**"
      ],
      "metadata": {
        "id": "WzqkdqqjX9gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Logistic Regression\n",
        "lr = LogisticRegression(max_iter=2000)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred = lr.predict(X_valid)\n",
        "y_pred_prob = lr.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Performance Evaluation\n",
        "print(\"\\n=== Logistic Regression Performance ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_valid, y_pred))\n",
        "print(\"AUC:\", roc_auc_score(y_valid, y_pred_prob))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_valid, y_pred))\n",
        "\n",
        "# Interpret Coefficients\n",
        "coef_df = pd.DataFrame({\n",
        "    \"feature\": X.columns,\n",
        "    \"coefficient\": lr.coef_[0]\n",
        "}).sort_values(by=\"coefficient\", ascending=False)\n",
        "\n",
        "print(\"\\n=== Top Positive Coefficients (higher default risk) ===\")\n",
        "print(coef_df.head(10))\n",
        "\n",
        "print(\"\\n=== Top Negative Coefficients (lower default risk) ===\")\n",
        "print(coef_df.tail(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmFmfQtFYWxL",
        "outputId": "68502b05-baff-476e-a356-4ebe75af002d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression Performance ===\n",
            "Accuracy: 0.9393449251920744\n",
            "AUC: 0.8213424964803017\n",
            "Confusion Matrix:\n",
            " [[2270   20]\n",
            " [ 130   53]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.99      0.97      2290\n",
            "         1.0       0.73      0.29      0.41       183\n",
            "\n",
            "    accuracy                           0.94      2473\n",
            "   macro avg       0.84      0.64      0.69      2473\n",
            "weighted avg       0.93      0.94      0.93      2473\n",
            "\n",
            "\n",
            "=== Top Positive Coefficients (higher default risk) ===\n",
            "                               feature  coefficient\n",
            "13                            uti_card     0.558554\n",
            "5   non_mtg_acc_past_due_12_months_num     0.464246\n",
            "1                        avg_card_debt     0.371700\n",
            "9                     inq_12_month_num     0.274913\n",
            "7      mortgages_past_due_6_months_num     0.258833\n",
            "6    non_mtg_acc_past_due_6_months_num     0.168581\n",
            "16                 uti_card_50plus_pct     0.106207\n",
            "11              card_open_36_month_num     0.058255\n",
            "24                           States_SC     0.035644\n",
            "10               card_inq_24_month_num     0.031314\n",
            "\n",
            "=== Top Negative Coefficients (lower default risk) ===\n",
            "                   feature  coefficient\n",
            "20               States_GA    -0.023513\n",
            "23               States_NC    -0.026882\n",
            "19               States_FL    -0.031808\n",
            "3          credit_good_age    -0.043391\n",
            "18              rep_income    -0.044453\n",
            "17             ind_acc_XYZ    -0.075338\n",
            "8   credit_past_due_amount    -0.089570\n",
            "4                 card_age    -0.186648\n",
            "2               credit_age    -0.215182\n",
            "0          tot_credit_debt    -0.293870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Random Forest Model**"
      ],
      "metadata": {
        "id": "Sk2oxJsYdNEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize Random Forest model\n",
        "# Explanation of hyperparameters:\n",
        "# - n_estimators: number of trees in the forest\n",
        "# - max_depth: maximum depth of each tree (None = expand fully)\n",
        "# - min_samples_leaf: minimum samples in a leaf node (larger value reduces overfitting)\n",
        "# - class_weight=\"balanced\": adjust for potential class imbalance (defaults vs non-defaults)\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=10,\n",
        "    random_state=0,\n",
        "    class_weight=\"balanced\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit model on training data\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation data\n",
        "y_valid_pred = rf.predict(X_valid)\n",
        "y_valid_prob = rf.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\n=== Random Forest Performance ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_valid, y_valid_pred))\n",
        "print(\"AUC:\", roc_auc_score(y_valid, y_valid_prob))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_valid_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_valid, y_valid_pred))\n",
        "\n",
        "# Feature importance\n",
        "importances = rf.feature_importances_\n",
        "feat_importance_df = pd.DataFrame({\n",
        "    \"feature\": X.columns,\n",
        "    \"importance\": importances\n",
        "}).sort_values(by=\"importance\", ascending=False)\n",
        "\n",
        "print(\"\\n=== Top 15 Most Important Features (Random Forest) ===\")\n",
        "print(feat_importance_df.head(15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpXFqBG_dV-u",
        "outputId": "540f9a9d-3cd6-45df-deb5-2392e3b40091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Random Forest Performance ===\n",
            "Accuracy: 0.9219571370804691\n",
            "AUC: 0.8604338177392798\n",
            "Confusion Matrix:\n",
            " [[2194   96]\n",
            " [  97   86]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.96      0.96      2290\n",
            "         1.0       0.47      0.47      0.47       183\n",
            "\n",
            "    accuracy                           0.92      2473\n",
            "   macro avg       0.72      0.71      0.71      2473\n",
            "weighted avg       0.92      0.92      0.92      2473\n",
            "\n",
            "\n",
            "=== Top 15 Most Important Features (Random Forest) ===\n",
            "                               feature  importance\n",
            "1                        avg_card_debt    0.172532\n",
            "13                            uti_card    0.095343\n",
            "0                      tot_credit_debt    0.076144\n",
            "5   non_mtg_acc_past_due_12_months_num    0.074857\n",
            "16                 uti_card_50plus_pct    0.074430\n",
            "8               credit_past_due_amount    0.059742\n",
            "4                             card_age    0.054864\n",
            "14                      uti_50plus_pct    0.054545\n",
            "2                           credit_age    0.052914\n",
            "15                 uti_max_credit_line    0.051537\n",
            "7      mortgages_past_due_6_months_num    0.049870\n",
            "3                      credit_good_age    0.045122\n",
            "18                          rep_income    0.034216\n",
            "6    non_mtg_acc_past_due_6_months_num    0.031918\n",
            "10               card_inq_24_month_num    0.024445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Final Random Forest**"
      ],
      "metadata": {
        "id": "rjYxCzrxm3FB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "# Manually define a small set of candidate parameter combinations\n",
        "param_grid = [\n",
        "    {\"n_estimators\": 200, \"max_depth\": None, \"min_samples_leaf\": 10},\n",
        "    {\"n_estimators\": 300, \"max_depth\": 8,    \"min_samples_leaf\": 10},\n",
        "    {\"n_estimators\": 300, \"max_depth\": 10,   \"min_samples_leaf\": 5},\n",
        "    {\"n_estimators\": 400, \"max_depth\": 8,    \"min_samples_leaf\": 5},\n",
        "    {\"n_estimators\": 500, \"max_depth\": 10,   \"min_samples_leaf\": 5},\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for params in param_grid:\n",
        "    print(\"\\nTrying params:\", params)\n",
        "\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=params[\"n_estimators\"],\n",
        "        max_depth=params[\"max_depth\"],\n",
        "        min_samples_leaf=params[\"min_samples_leaf\"],\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=0,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_valid_prob = rf.predict_proba(X_valid)[:, 1]\n",
        "    y_valid_pred = rf.predict(X_valid)\n",
        "\n",
        "    auc = roc_auc_score(y_valid, y_valid_prob)\n",
        "    acc = accuracy_score(y_valid, y_valid_pred)\n",
        "\n",
        "    print(f\"Validation AUC = {auc:.4f}, Accuracy = {acc:.4f}\")\n",
        "\n",
        "    results.append({\n",
        "        \"params\": params,\n",
        "        \"auc\": auc,\n",
        "        \"accuracy\": acc\n",
        "    })\n",
        "\n",
        "# Identify the parameter combination with the highest AUC\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nAll candidates:\")\n",
        "print(results_df)\n",
        "\n",
        "best_row = results_df.iloc[results_df[\"auc\"].idxmax()]\n",
        "best_params = best_row[\"params\"]\n",
        "print(\"\\nBest params by validation AUC:\")\n",
        "print(best_params)\n",
        "print(\"Best AUC:\", best_row[\"auc\"])\n",
        "\n",
        "best_params = {'n_estimators': 400, 'max_depth': 8, 'min_samples_leaf': 5}\n",
        "\n",
        "final_rf = RandomForestClassifier(\n",
        "    n_estimators=best_params[\"n_estimators\"],\n",
        "    max_depth=best_params[\"max_depth\"],\n",
        "    min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=0,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "final_rf.fit(X_scaled, y)\n",
        "\n",
        "print(\"Final Random Forest trained on all available data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "343MKGeenIL4",
        "outputId": "4cfc4c88-549b-458a-e15d-fbd599425be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trying params: {'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}\n",
            "Validation AUC = 0.8583, Accuracy = 0.9211\n",
            "\n",
            "Trying params: {'n_estimators': 300, 'max_depth': 8, 'min_samples_leaf': 10}\n",
            "Validation AUC = 0.8593, Accuracy = 0.8908\n",
            "\n",
            "Trying params: {'n_estimators': 300, 'max_depth': 10, 'min_samples_leaf': 5}\n",
            "Validation AUC = 0.8579, Accuracy = 0.9163\n",
            "\n",
            "Trying params: {'n_estimators': 400, 'max_depth': 8, 'min_samples_leaf': 5}\n",
            "Validation AUC = 0.8593, Accuracy = 0.8941\n",
            "\n",
            "Trying params: {'n_estimators': 500, 'max_depth': 10, 'min_samples_leaf': 5}\n",
            "Validation AUC = 0.8579, Accuracy = 0.9171\n",
            "\n",
            "All candidates:\n",
            "                                              params       auc  accuracy\n",
            "0  {'n_estimators': 200, 'max_depth': None, 'min_...  0.858339  0.921148\n",
            "1  {'n_estimators': 300, 'max_depth': 8, 'min_sam...  0.859284  0.890821\n",
            "2  {'n_estimators': 300, 'max_depth': 10, 'min_sa...  0.857926  0.916296\n",
            "3  {'n_estimators': 400, 'max_depth': 8, 'min_sam...  0.859317  0.894056\n",
            "4  {'n_estimators': 500, 'max_depth': 10, 'min_sa...  0.857897  0.917105\n",
            "\n",
            "Best params by validation AUC:\n",
            "{'n_estimators': 400, 'max_depth': 8, 'min_samples_leaf': 5}\n",
            "Best AUC: 0.8593170592025198\n",
            "Final Random Forest trained on all available data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Demo: Credit Card Applications**"
      ],
      "metadata": {
        "id": "JYBX5zh5M-SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "best_params = {'n_estimators': 400, 'max_depth': 8, 'min_samples_leaf': 5}\n",
        "\n",
        "best_rf = RandomForestClassifier(\n",
        "    n_estimators=best_params[\"n_estimators\"],\n",
        "    max_depth=best_params[\"max_depth\"],\n",
        "    min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=0,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "y_valid_prob = best_rf.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Compute default probability for validation set\n",
        "y_valid_prob = best_rf.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Show first 20 probabilities\n",
        "import numpy as np\n",
        "print(\"First 20 predicted default probabilities:\\n\")\n",
        "print(np.round(y_valid_prob[:20], 4))\n",
        "\n",
        "# Organize the probability of default into a readable table\n",
        "import pandas as pd\n",
        "\n",
        "prob_df = pd.DataFrame({\n",
        "    \"Default_Probability\": y_valid_prob\n",
        "})\n",
        "\n",
        "print(prob_df.head(20))\n",
        "\n",
        "# Automatically generate risk levels\n",
        "def risk_band(p):\n",
        "    if p < 0.10:\n",
        "        return \"Low Risk\"\n",
        "    elif p < 0.25:\n",
        "        return \"Medium Risk\"\n",
        "    else:\n",
        "        return \"High Risk\"\n",
        "\n",
        "prob_df[\"Risk_Band\"] = prob_df[\"Default_Probability\"].apply(risk_band)\n",
        "\n",
        "print(prob_df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH-BoGe7NpI9",
        "outputId": "e647c799-84ac-47b3-962e-c6f90ef49bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 20 predicted default probabilities:\n",
            "\n",
            "[0.2909 0.2672 0.2365 0.2156 0.0841 0.5754 0.1819 0.4081 0.2383 0.2243\n",
            " 0.1741 0.0609 0.1146 0.1379 0.4388 0.1672 0.2221 0.8857 0.2473 0.2412]\n",
            "    Default_Probability\n",
            "0              0.290919\n",
            "1              0.267221\n",
            "2              0.236455\n",
            "3              0.215630\n",
            "4              0.084137\n",
            "5              0.575353\n",
            "6              0.181931\n",
            "7              0.408136\n",
            "8              0.238256\n",
            "9              0.224316\n",
            "10             0.174110\n",
            "11             0.060866\n",
            "12             0.114589\n",
            "13             0.137940\n",
            "14             0.438838\n",
            "15             0.167231\n",
            "16             0.222109\n",
            "17             0.885744\n",
            "18             0.247338\n",
            "19             0.241154\n",
            "    Default_Probability    Risk_Band\n",
            "0              0.290919    High Risk\n",
            "1              0.267221    High Risk\n",
            "2              0.236455  Medium Risk\n",
            "3              0.215630  Medium Risk\n",
            "4              0.084137     Low Risk\n",
            "5              0.575353    High Risk\n",
            "6              0.181931  Medium Risk\n",
            "7              0.408136    High Risk\n",
            "8              0.238256  Medium Risk\n",
            "9              0.224316  Medium Risk\n",
            "10             0.174110  Medium Risk\n",
            "11             0.060866     Low Risk\n",
            "12             0.114589  Medium Risk\n",
            "13             0.137940  Medium Risk\n",
            "14             0.438838    High Risk\n",
            "15             0.167231  Medium Risk\n",
            "16             0.222109  Medium Risk\n",
            "17             0.885744    High Risk\n",
            "18             0.247338  Medium Risk\n",
            "19             0.241154  Medium Risk\n"
          ]
        }
      ]
    }
  ]
}